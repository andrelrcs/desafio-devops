# üöÄ CSV Processor - Infraestrutura AWS Serverless

Solu√ß√£o completa para processamento de arquivos CSV na AWS usando Lambda, S3 e infraestrutura como c√≥digo (Terraform).

## üìã √çndice

- [Vis√£o Geral](#vis√£o-geral)
- [Arquitetura](#arquitetura)
- [Pr√©-requisitos](#pr√©-requisitos)
- [Instala√ß√£o e Deploy](#instala√ß√£o-e-deploy)
- [Uso](#uso)
- [Monitoramento](#monitoramento)
- [CI/CD](#cicd)
- [Seguran√ßa](#seguran√ßa)
- [Custos](#custos)
- [Troubleshooting](#troubleshooting)

---

## üéØ Vis√£o Geral

Este projeto moderniza uma aplica√ß√£o Python legada que processa arquivos CSV da tabela FIPE, calculando pre√ßos m√©dios de ve√≠culos agrupados por ano e marca.

### Funcionalidades

- ‚úÖ Processamento autom√°tico de CSV via S3 events
- ‚úÖ Arquitetura serverless (AWS Lambda)
- ‚úÖ Infraestrutura como c√≥digo (Terraform)
- ‚úÖ CI/CD com GitHub Actions
- ‚úÖ Monitoramento com CloudWatch
- ‚úÖ Seguran√ßa (IAM least privilege, encryption)
- ‚úÖ Containeriza√ß√£o com Docker

---

## üèóÔ∏è Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      S3 Event      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      Write JSON      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  S3 Input   ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> ‚îÇ Lambda (ECR) ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>  ‚îÇ S3 Output   ‚îÇ
‚îÇ   Bucket    ‚îÇ                     ‚îÇ  Container   ‚îÇ                      ‚îÇ   Bucket    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                            ‚îÇ
                                            ‚îÇ Logs
                                            ‚ñº
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ  CloudWatch  ‚îÇ
                                    ‚îÇ  Logs/Alarms ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes

| Componente | Descri√ß√£o | Justificativa |
|------------|-----------|---------------|
| **AWS Lambda** | Executa processamento | Event-driven, custo-benef√≠cio para workload intermitente |
| **S3** | Armazenamento de arquivos | Dur√°vel, escal√°vel, trigger nativo |
| **ECR** | Registry de containers | Imagens Docker versionadas |
| **CloudWatch** | Logs e m√©tricas | Observabilidade integrada |
| **IAM** | Controle de acesso | Least privilege, seguran√ßa |

Para detalhes da decis√£o arquitetural, veja [ARCHITECTURE.md](ARCHITECTURE.md).

---

## üì¶ Pr√©-requisitos

### Software Necess√°rio

- **AWS CLI** (v2.x): [Instala√ß√£o](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)
- **Terraform** (>= 1.6.0): [Instala√ß√£o](https://developer.hashicorp.com/terraform/downloads)
- **Docker** (>= 20.x): [Instala√ß√£o](https://docs.docker.com/get-docker/)
- **Git**: [Instala√ß√£o](https://git-scm.com/downloads)

### Conta AWS

- Conta AWS ativa
- Credenciais configuradas com permiss√µes para:
  - S3, Lambda, ECR, IAM, CloudWatch, EC2 (VPC - se necess√°rio)

### Configura√ß√£o AWS CLI

```bash
aws configure
# AWS Access Key ID: YOUR_ACCESS_KEY
# AWS Secret Access Key: YOUR_SECRET_KEY
# Default region: us-east-1
# Default output format: json
```

---

## üöÄ Instala√ß√£o e Deploy

### Op√ß√£o 1: Deploy Manual (Primeiro Deploy)

#### 1. Clone o Reposit√≥rio

```bash
git clone https://github.com/your-username/desafio-devops.git
cd desafio-devops
```

#### 2. Crie o Reposit√≥rio ECR Manualmente (Primeira Vez)

```bash
# Defina vari√°veis
export AWS_REGION=us-east-1
export AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
export ENVIRONMENT=dev
export REPOSITORY_NAME=csv-processor-${ENVIRONMENT}

# Crie o reposit√≥rio ECR
aws ecr create-repository \
  --repository-name ${REPOSITORY_NAME} \
  --region ${AWS_REGION} \
  --image-scanning-configuration scanOnPush=true \
  --encryption-configuration encryptionType=AES256
```

#### 3. Build e Push da Imagem Docker

```bash
# Login no ECR
aws ecr get-login-password --region ${AWS_REGION} | \
  docker login --username AWS --password-stdin ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com

# Build da imagem
docker build -t ${REPOSITORY_NAME}:latest .

# Tag da imagem
docker tag ${REPOSITORY_NAME}:latest \
  ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${REPOSITORY_NAME}:latest

# Push da imagem
docker push ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${REPOSITORY_NAME}:latest
```

#### 4. Deploy da Infraestrutura com Terraform

```bash
# Inicialize o Terraform
terraform init

# Valide a configura√ß√£o
terraform validate

# Visualize o plano de execu√ß√£o
terraform plan \
  -var="environment=${ENVIRONMENT}" \
  -var="aws_region=${AWS_REGION}" \
  -var="lambda_image_uri=${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${REPOSITORY_NAME}:latest"

# Aplique a infraestrutura
terraform apply \
  -var="environment=${ENVIRONMENT}" \
  -var="aws_region=${AWS_REGION}" \
  -var="lambda_image_uri=${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${REPOSITORY_NAME}:latest" \
  -auto-approve
```

#### 5. Capture os Outputs

```bash
# Salve os outputs importantes
terraform output > terraform_outputs.txt

# Ou acesse outputs espec√≠ficos
export INPUT_BUCKET=$(terraform output -raw input_bucket_name)
export OUTPUT_BUCKET=$(terraform output -raw output_bucket_name)
export LAMBDA_FUNCTION=$(terraform output -raw lambda_function_name)

echo "Input Bucket: $INPUT_BUCKET"
echo "Output Bucket: $OUTPUT_BUCKET"
echo "Lambda Function: $LAMBDA_FUNCTION"
```

### Op√ß√£o 2: Deploy Automatizado (CI/CD)

Para deploys subsequentes, use o pipeline GitHub Actions (veja se√ß√£o [CI/CD](#cicd)).

---

## üíª Uso

### Processar um Arquivo CSV

#### 1. Upload Manual via AWS CLI

```bash
# Upload do arquivo CSV
aws s3 cp tabela-fipe-historico-precos.csv s3://${INPUT_BUCKET}/

# Aguarde o processamento (autom√°tico via S3 event)
sleep 10

# Verifique o arquivo de sa√≠da
aws s3 ls s3://${OUTPUT_BUCKET}/

# Download do resultado
aws s3 cp s3://${OUTPUT_BUCKET}/tabela-fipe-historico-precos_preco_medio.json .
```

#### 2. Upload via Console AWS

1. Acesse o [S3 Console](https://console.aws.amazon.com/s3/)
2. Navegue at√© o bucket de input (ex: `csv-processor-dev-input-xxxxx`)
3. Clique em **Upload** ‚Üí Selecione seu arquivo CSV
4. Aguarde o processamento
5. Verifique o bucket de output

#### 3. Upload Program√°tico (Python)

```python
import boto3

s3 = boto3.client('s3')

# Upload
s3.upload_file(
    'local-file.csv',
    'csv-processor-dev-input-xxxxx',
    'local-file.csv'
)

# Download do resultado ap√≥s processamento
s3.download_file(
    'csv-processor-dev-output-xxxxx',
    'local-file_preco_medio.json',
    'output.json'
)
```

### Formato do Arquivo CSV de Entrada

O CSV deve conter as seguintes colunas:

```csv
codigoFipe,marca,modelo,anoModelo,mesReferencia,anoReferencia,valor
001016-1,Acura,Integra GS 1.8,1992,janeiro,1992,12104.23
002100-5,Audi,80 2.0,1995,fevereiro,1995,14567.89
```

### Formato do JSON de Sa√≠da

```json
{
  "1992": {
    "Acura": 12104.23,
    "Audi": 14567.89
  },
  "1995": {
    "Acura": 49296.0
  }
}
```

---

## üìä Monitoramento

### CloudWatch Logs

```bash
# Visualizar logs em tempo real
aws logs tail /aws/lambda/${LAMBDA_FUNCTION} --follow

# √öltimas 50 linhas
aws logs tail /aws/lambda/${LAMBDA_FUNCTION} --since 1h

# Filtrar por erro
aws logs filter-log-events \
  --log-group-name /aws/lambda/${LAMBDA_FUNCTION} \
  --filter-pattern "ERROR"
```

### CloudWatch Metrics

Acesse o [CloudWatch Console](https://console.aws.amazon.com/cloudwatch/) para visualizar:

- **Invoca√ß√µes**: N√∫mero de execu√ß√µes
- **Dura√ß√£o**: Tempo m√©dio de processamento
- **Erros**: Taxa de falhas
- **Throttles**: Limita√ß√µes de concorr√™ncia

### CloudWatch Alarms

Alarmes configurados automaticamente:

| Alarme | Condi√ß√£o | A√ß√£o |
|--------|----------|------|
| High Error Rate | Taxa de erro > 5% | Email notification |
| High Duration | Dura√ß√£o > 3 minutos | Email notification |
| Throttles | Throttling detectado | Email notification |

Para configurar email de notifica√ß√µes:

```bash
terraform apply -var="alarm_email=seu-email@example.com"
```

### Dashboard

Acesse o dashboard no CloudWatch:

```bash
# URL do dashboard
echo "https://${AWS_REGION}.console.aws.amazon.com/cloudwatch/home?region=${AWS_REGION}#dashboards:name=csv-processor-${ENVIRONMENT}-lambda-dashboard"
```

---

## üîÑ CI/CD

### GitHub Actions Pipeline

O pipeline automatiza:

1. **Validate**: Lint do c√≥digo, valida√ß√£o Terraform
2. **Build**: Build e push da imagem Docker para ECR
3. **Deploy**: Deploy da infraestrutura e atualiza√ß√£o da Lambda
4. **Test**: Testes de integra√ß√£o

### Configura√ß√£o

#### 1. Adicione Secrets no GitHub

V√° em: `Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí New repository secret`

Adicione:

- `AWS_ACCESS_KEY_ID`: Sua AWS Access Key
- `AWS_SECRET_ACCESS_KEY`: Sua AWS Secret Key

#### 2. Triggers

O pipeline executa:

- **Push para `main`**: Deploy em produ√ß√£o
- **Push para `develop`**: Deploy em desenvolvimento
- **Pull Request**: Valida√ß√£o e testes
- **Manual**: Dispatch manual com sele√ß√£o de ambiente

#### 3. Executar Manualmente

```bash
# Via GitHub UI
Actions ‚Üí Deploy to AWS ‚Üí Run workflow ‚Üí Selecione environment

# Via GitHub CLI
gh workflow run deploy.yml -f environment=dev
```

### Ambientes

| Branch | Ambiente | Deploy Autom√°tico |
|--------|----------|-------------------|
| `main` | prod | ‚úÖ Sim |
| `develop` | dev | ‚úÖ Sim |
| `feature/*` | - | ‚ùå Apenas valida√ß√£o |

---

## üîí Seguran√ßa

### Princ√≠pios Implementados

#### 1. Least Privilege (IAM)

Lambda tem apenas as permiss√µes necess√°rias:

```
‚úÖ s3:GetObject no input bucket
‚úÖ s3:PutObject no output bucket
‚úÖ logs:CreateLogStream, logs:PutLogEvents
‚ùå Sem s3:DeleteObject
‚ùå Sem acesso a outros servi√ßos
```

#### 2. Encryption

- **S3**: Server-Side Encryption (SSE-S3)
- **ECR**: Encryption at rest (AES256)
- **CloudWatch Logs**: Encryption in transit

#### 3. Network Security

- **S3 Buckets**: Block all public access
- **Lambda**: Sem acesso p√∫blico (trigger apenas via S3)

#### 4. Secrets Management

Nunca commite credenciais! Use:

- **AWS Secrets Manager** para secrets (API keys, DB passwords)
- **Environment variables** para configura√ß√µes n√£o-sens√≠veis

```bash
# Adicionar secret
aws secretsmanager create-secret \
  --name csv-processor/${ENVIRONMENT}/api-key \
  --secret-string "your-secret-value"

# Atualizar Lambda para usar o secret
# (adicione permiss√£o secretsmanager:GetSecretValue no IAM)
```

### Security Best Practices

- ‚úÖ Use MFA na conta AWS
- ‚úÖ Rotacione access keys regularmente
- ‚úÖ Habilite AWS CloudTrail para auditoria
- ‚úÖ Use AWS Config para compliance
- ‚úÖ Escanear imagens Docker (Trivy no CI/CD)

---

## üí∞ Custos

### Estimativa Mensal

Para **1000 processamentos/m√™s** (CSV ~10MB, tempo de execu√ß√£o ~30s):

| Servi√ßo | Uso | Custo |
|---------|-----|-------|
| Lambda | 1000 invoca√ß√µes √ó 30s √ó 512MB | $0.50 |
| S3 Storage | 1GB input + 1GB output | $0.05 |
| S3 Requests | 2000 requests | $0.01 |
| ECR | 500MB imagem | $0.05 |
| CloudWatch | Logs + Metrics | $0.50 |
| Data Transfer | Minimal | $0.05 |
| **Total** | | **~$1.20/m√™s** |

### Free Tier

AWS oferece:

- **Lambda**: 1M requests/m√™s + 400.000 GB-seconds/m√™s
- **S3**: 5GB storage + 20.000 GET requests
- **ECR**: 500MB storage/m√™s (12 meses)

**Conclus√£o**: Para baixo volume, o custo pode ser **$0** (free tier).

### Otimiza√ß√£o de Custos

1. **Lambda Memory**: Ajuste para o m√≠nimo necess√°rio
2. **S3 Lifecycle**: Mova dados antigos para Glacier
3. **CloudWatch Logs**: Reduza reten√ß√£o para 3-7 dias
4. **ECR Lifecycle**: Mantenha apenas √∫ltimas 5 imagens

```bash
# Ajustar mem√≥ria da Lambda
terraform apply -var="lambda_memory_size=256"

# Ajustar reten√ß√£o de logs
terraform apply -var="log_retention_days=3"
```

---

## üêõ Troubleshooting

### Problemas Comuns

#### 1. Lambda n√£o √© invocada ap√≥s upload do CSV

**Sintomas**: Arquivo enviado, mas nenhum processamento ocorre.

**Solu√ß√µes**:

```bash
# Verifique se o trigger S3 est√° configurado
aws lambda list-event-source-mappings \
  --function-name ${LAMBDA_FUNCTION}

# Verifique logs
aws logs tail /aws/lambda/${LAMBDA_FUNCTION} --since 5m

# Teste manualmente
aws lambda invoke \
  --function-name ${LAMBDA_FUNCTION} \
  --payload '{"Records":[{"s3":{"bucket":{"name":"'${INPUT_BUCKET}'"},"object":{"key":"test.csv"}}}]}' \
  response.json
```

#### 2. Erro "Access Denied" ao escrever no S3

**Causa**: Permiss√µes IAM insuficientes.

**Solu√ß√£o**:

```bash
# Verifique a policy IAM
aws iam get-role-policy \
  --role-name csv-processor-dev-lambda-role \
  --policy-name csv-processor-dev-lambda-s3-policy

# Reaplique o Terraform
terraform apply
```

#### 3. Lambda timeout

**Causa**: Arquivo muito grande ou processamento lento.

**Solu√ß√£o**:

```bash
# Aumente timeout e mem√≥ria
terraform apply \
  -var="lambda_timeout=600" \
  -var="lambda_memory_size=1024"
```

#### 4. Imagem Docker n√£o encontrada

**Causa**: Imagem n√£o foi enviada para ECR ou URI incorreta.

**Solu√ß√£o**:

```bash
# Liste imagens no ECR
aws ecr list-images --repository-name ${REPOSITORY_NAME}

# Reconstrua e envie
docker build -t ${REPOSITORY_NAME}:latest .
docker push ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${REPOSITORY_NAME}:latest

# Atualize Lambda
aws lambda update-function-code \
  --function-name ${LAMBDA_FUNCTION} \
  --image-uri ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${REPOSITORY_NAME}:latest
```

#### 5. Terraform state locked

**Causa**: Outro terraform apply est√° rodando ou foi interrompido.

**Solu√ß√£o**:

```bash
# Force unlock (use com cuidado!)
terraform force-unlock <LOCK_ID>

# Ou delete o lock manualmente no S3/DynamoDB backend
```

### Logs de Debug

```bash
# Habilite debug logging
terraform apply -var="lambda_log_level=DEBUG"

# Visualize logs detalhados
aws logs tail /aws/lambda/${LAMBDA_FUNCTION} --follow --format detailed
```

---

## üß™ Testes

### Teste Local (Docker)

```bash
# Build local
docker build -t csv-processor:test .

# Execute localmente
docker run -p 9000:8080 csv-processor:test

# Em outro terminal, invoque
curl -XPOST "http://localhost:9000/2015-03-31/functions/function/invocations" \
  -d '{"Records":[{"s3":{"bucket":{"name":"test"},"object":{"key":"test.csv"}}}]}'
```

### Teste na AWS

```bash
# Upload de arquivo teste
echo "codigoFipe,marca,modelo,anoModelo,mesReferencia,anoReferencia,valor" > test.csv
echo "001,TestBrand,TestModel,2020,01,2020,50000.00" >> test.csv

aws s3 cp test.csv s3://${INPUT_BUCKET}/test.csv

# Aguarde processamento
sleep 10

# Verifique resultado
aws s3 cp s3://${OUTPUT_BUCKET}/test_preco_medio.json - | jq .

# Cleanup
aws s3 rm s3://${INPUT_BUCKET}/test.csv
aws s3 rm s3://${OUTPUT_BUCKET}/test_preco_medio.json
```

---

## üóëÔ∏è Destrui√ß√£o da Infraestrutura

**‚ö†Ô∏è ATEN√á√ÉO**: Esta a√ß√£o √© **irrevers√≠vel** e deletar√° todos os recursos.

```bash
# Visualize o que ser√° destru√≠do
terraform plan -destroy

# Destrua a infraestrutura
terraform destroy -auto-approve

# Limpe buckets S3 manualmente (se necess√°rio)
aws s3 rb s3://${INPUT_BUCKET} --force
aws s3 rb s3://${OUTPUT_BUCKET} --force

# Delete reposit√≥rio ECR
aws ecr delete-repository \
  --repository-name ${REPOSITORY_NAME} \
  --force
```

---

## üìö Documenta√ß√£o Adicional

- [Decis√µes Arquiteturais](ARCHITECTURE.md)
- [Documenta√ß√£o da Aplica√ß√£o Original](https://github.com/rafaelmedeirosenacom/desafio-devops)
- [AWS Lambda Documentation](https://docs.aws.amazon.com/lambda/)
- [Terraform AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)

---

## ü§ù Contribuindo

1. Fork o reposit√≥rio
2. Crie uma branch: `git checkout -b feature/nova-funcionalidade`
3. Commit: `git commit -am 'Add nova funcionalidade'`
4. Push: `git push origin feature/nova-funcionalidade`
5. Abra um Pull Request

---

## üìù Licen√ßa

Este projeto √© open source e est√° sob a licen√ßa MIT.

---

## üë• Autores

- **Seu Nome** - DevOps Engineer
- Baseado no desafio de [rafaelmedeirosenacom](https://github.com/rafaelmedeirosenacom/desafio-devops)

---

## üéØ Status do Projeto

‚úÖ Infraestrutura provisionada via Terraform  
‚úÖ Aplica√ß√£o containerizada  
‚úÖ CI/CD implementado  
‚úÖ Monitoramento configurado  
‚úÖ Seguran√ßa implementada (least privilege)  
‚úÖ Documenta√ß√£o completa  

---

**üöÄ Deploy realizado com sucesso! Happy coding!**